{"cells":[{"cell_type":"markdown","source":["**FINAL PROJECT: Airline Market Analysis..**<br>\n**ALY 6110: Data Management and Big Data**<br>\n**Group BETA**<br>\nGroup Members<br>\n1.Ashwini Kumar Pathak [pathak.as@husky.neu.edu] <br>\n2.Ayush Jain [jain.ayush@husky.neu.edu]<br>\n3.Megha Ravi [ravi.m@husky.neu.edu]<br>\n4.Ashishkumar Bidap [bidap.a@husky.neu.edu]<br>"],"metadata":{}},{"cell_type":"code","source":["dbutils.fs.unmount(\"/mnt/flight_data\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/mnt/flight_data has been unmounted.\nOut[57]: True</div>"]}}],"execution_count":2},{"cell_type":"code","source":["import urllib\n\n#CONNECTING WITH AWS IN ORDER TO ACCESS S3 FILES.\nACCESS_KEY = \"XXXX\"\nSECRET_KEY = \"XXXX\"\nENCODED_SECRET_KEY = SECRET_KEY.replace(\"/\", \"%2F\")\nAWS_BUCKET_NAME = \"airplane-data-bigdata\"\nMOUNT_NAME = \"flight_data\"\n\ndbutils.fs.mount(\"s3a://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)\ndisplay(dbutils.fs.ls(\"/mnt/%s\" % MOUNT_NAME))"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#LIST OF FILES \ndisplay(dbutils.fs.ls(\"/mnt/flight_data/airplane_data\"))"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["flight_merged_data = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/mnt/flight_data/airplane_data/airOT20*.csv\")"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["flight_merged_data.count()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["flight_merged_data.select('YEAR').distinct().show()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["The above count queries are taking more time to execute as the whole table is getting traversed,thus there is a need of optimization over these dataframes."],"metadata":{}},{"cell_type":"code","source":["flight_merged_data.rdd.getNumPartitions()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["Above shown are the default Number of Partitions done by the Spark and there is a need to optimize the partition size for the dataframes."],"metadata":{}},{"cell_type":"code","source":["flight_merged_data.repartition(63).createOrReplaceTempView(\"flight_merged_view\")"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["Caching the dataframe to memeory with uodated number of partitions for faster execution."],"metadata":{}},{"cell_type":"code","source":["spark.catalog.cacheTable('flight_merged_view')"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["spark.table(\"flight_merged_view\").count()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["This cache creation is done once an action query is triggered on the particular table."],"metadata":{}},{"cell_type":"code","source":["flight_merged_DF = spark.table(\"flight_merged_view\")"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["As our final dataframe with optimized number of partitions is ready we have saved a parquet file of the data for future use so we can continue with the same file even if the cluster terminates."],"metadata":{}},{"cell_type":"code","source":["flight_merged_DF.write.format('parquet').save('/tmp/flight_merged_parquet/')"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["display(dbutils.fs.ls(\"/tmp/flight_merged_parquet\"))"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["Setting Up the Deafult setting of Shuffle Partitions.."],"metadata":{}},{"cell_type":"code","source":["spark.conf.get(\"spark.sql.shuffle.partitions\")"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.shuffle.partitions\",63)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["As we created a merged optimized dataframe,we have saved a \"parquet\" file of the dataframe with the updated number of partitions.Parquet is a columnar file format that provides optimizations to speed up queries and is a far more efficient file format than CSV or JSON, supported by many data processing systems.\n<br>\nLater even if the cluster terminates we can use the newly created parquet file with the updated number of partitions."],"metadata":{}},{"cell_type":"markdown","source":["# Exploratory Data Analysis of the Data."],"metadata":{}},{"cell_type":"markdown","source":["Count of Flights Against each destination state in the United States from Jan 2000 - Feb 2020.\n- California and Texas have maximum number of incoming flights."],"metadata":{}},{"cell_type":"code","source":["query1 = spark.sql(\"SELECT COUNT(*) AS FLIGHTS, DEST_STATE_ABR FROM flight_merged_view GROUP BY DEST_STATE_ABR ORDER BY FLIGHTS DESC LIMIT 20\")\ndisplay(query1)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>FLIGHTS</th><th>DEST_STATE_ABR</th></tr></thead><tbody><tr><td>15425336</td><td>CA</td></tr><tr><td>14449778</td><td>TX</td></tr><tr><td>8989110</td><td>FL</td></tr><tr><td>8486472</td><td>IL</td></tr><tr><td>7884760</td><td>GA</td></tr><tr><td>5902895</td><td>NY</td></tr><tr><td>4689134</td><td>CO</td></tr><tr><td>4140333</td><td>NC</td></tr><tr><td>4111950</td><td>VA</td></tr><tr><td>4082632</td><td>AZ</td></tr><tr><td>3532586</td><td>NV</td></tr><tr><td>3458122</td><td>MI</td></tr><tr><td>3270881</td><td>PA</td></tr><tr><td>2819855</td><td>MN</td></tr><tr><td>2765681</td><td>MO</td></tr><tr><td>2636410</td><td>NJ</td></tr><tr><td>2577210</td><td>WA</td></tr><tr><td>2464310</td><td>MA</td></tr><tr><td>2425557</td><td>TN</td></tr><tr><td>2413319</td><td>UT</td></tr></tbody></table></div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["Comparing the possible causes of delays in the Flights."],"metadata":{}},{"cell_type":"code","source":["query3 = spark.sql(\"SELECT 'CARRIER_DELAY' AS FACTOR, (SELECT SUM(CARRIER_DELAY) FROM flight_merged_view) AS FLIGHT_DELAYS UNION SELECT 'WEATHER_DELAY' AS FACTOR, (SELECT SUM(WEATHER_DELAY) FROM flight_merged_view) AS FLIGHT_DELAYS UNION SELECT 'NAS_DELAY' AS FACTOR, (SELECT SUM(NAS_DELAY) FROM flight_merged_view) AS FLIGHT_DELAYS UNION SELECT 'SECURITY_DELAY' AS FACTOR, (SELECT SUM(SECURITY_DELAY) FROM flight_merged_view) AS FLIGHT_DELAYS UNION SELECT 'LATE_AIRCRAFT_DELAY' AS FACTOR, (SELECT SUM(LATE_AIRCRAFT_DELAY) FROM flight_merged_view) AS FLIGHT_DELAYS ORDER BY FLIGHT_DELAYS DESC\")\ndisplay(query3)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>FACTOR</th><th>FLIGHT_DELAYS</th></tr></thead><tbody><tr><td>LATE_AIRCRAFT_DELAY</td><td>4.65640739E8</td></tr><tr><td>CARRIER_DELAY</td><td>3.58894745E8</td></tr><tr><td>NAS_DELAY</td><td>3.27300129E8</td></tr><tr><td>WEATHER_DELAY</td><td>6.2387678E7</td></tr><tr><td>SECURITY_DELAY</td><td>1942565.0</td></tr></tbody></table></div>"]}}],"execution_count":28},{"cell_type":"markdown","source":["**Analysing the count of cancelled flights against the days of week.**<br>\n\n- Friday has comparatively less number of cancelled flights compared to other days of week."],"metadata":{}},{"cell_type":"code","source":["def intToDay(dayOfWeek):\n  switcher = {\n    1: 'SUN',\n    2: 'MON',\n    3: 'TUE',\n    4: 'WED',\n    5: 'THU',\n    6: 'FRI',\n    7: 'SAT'\n  }\n  return switcher.get(int(dayOfWeek), 'Invalid DAY_OF_WEEK')\n\nspark.udf.register(\"intToDay\", intToDay)\nquery4 = spark.sql(\"SELECT intToDay(DAY_OF_WEEK) AS WEEKDAY, DAY_OF_WEEK, SUM(CANCELLED) AS FLIGHTS_CANCELLED FROM flight_merged_view GROUP BY DAY_OF_WEEK ORDER BY FLIGHTS_CANCELLED DESC\")\ndisplay(query4)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>WEEKDAY</th><th>DAY_OF_WEEK</th><th>FLIGHTS_CANCELLED</th></tr></thead><tbody><tr><td>MON</td><td>2</td><td>378592.0</td></tr><tr><td>TUE</td><td>3</td><td>376648.0</td></tr><tr><td>WED</td><td>4</td><td>363834.0</td></tr><tr><td>SUN</td><td>1</td><td>351376.0</td></tr><tr><td>THU</td><td>5</td><td>339440.0</td></tr><tr><td>SAT</td><td>7</td><td>288615.0</td></tr><tr><td>FRI</td><td>6</td><td>236335.0</td></tr></tbody></table></div>"]}}],"execution_count":30},{"cell_type":"markdown","source":["**Total Number of FLights against each Month (Jan 2000 - Feb 2020)**<br>\n\n- June and July having maximum number of flight travels this should be becuase of the summer breaks."],"metadata":{}},{"cell_type":"code","source":["def intToMonth(month):\n  switcher = {\n    1: 'Jan',\n    2: 'Feb',\n    3: 'Mar',\n    4: 'Apr',\n    5: 'May',\n    6: 'Jun',\n    7: 'Jul',\n    8: 'Aug',\n    9: 'Sep',\n    10: 'Oct',\n    11: 'Nov',\n    12: 'Dec'\n  }\n  return switcher.get(int(month), 'Invalid MONTH')\n\nspark.udf.register(\"intToMonth\", intToMonth)\nquery5 = spark.sql(\"SELECT COUNT(*) AS FLIGHTS, intToMonth(MONTH) AS MONTH_NAME, MONTH FROM flight_merged_view GROUP BY MONTH ORDER BY FLIGHTS DESC\")\ndisplay(query5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>FLIGHTS</th><th>MONTH_NAME</th><th>MONTH</th></tr></thead><tbody><tr><td>11937664</td><td>Jun</td><td>6</td></tr><tr><td>11376394</td><td>Jul</td><td>7</td></tr><tr><td>11281939</td><td>Sep</td><td>9</td></tr><tr><td>11135746</td><td>Nov</td><td>11</td></tr><tr><td>11119794</td><td>Jan</td><td>1</td></tr><tr><td>11053120</td><td>Mar</td><td>3</td></tr><tr><td>10952679</td><td>May</td><td>5</td></tr><tr><td>10617396</td><td>Apr</td><td>4</td></tr><tr><td>10311516</td><td>Aug</td><td>8</td></tr><tr><td>9784417</td><td>Oct</td><td>10</td></tr><tr><td>9782928</td><td>Feb</td><td>2</td></tr><tr><td>9573186</td><td>Dec</td><td>12</td></tr></tbody></table></div>"]}}],"execution_count":32},{"cell_type":"markdown","source":["##Impact of Global Recession On the Airline Industry..!!\n\n<br>\nWhen housing prices fell and homeowners began to walk away from their mortgages, the value of mortgage-backed securities held by investment banks declined in 2007–2008, causing several to collapse on the economy of the United States in the years of 2008 and ahead....\n\nsource:wikipedia"],"metadata":{}},{"cell_type":"markdown","source":["**State wise frequency of the flights journey.**\n- Consistent fall in the Number of flights Journeys in the big states of US.<br>\n1.California <br>\n2.Texas<br>\n3.Illinois<br>\n3.Florida<br>\n4.New York<br>"],"metadata":{}},{"cell_type":"code","source":["#STATEWISE DISTRIBUTION FOR THE IMPACTED YEARS..!\ndisplay(spark.sql('select DEST_STATE_ABR,count(DEST_STATE_ABR) as Frequency_Flights,year from flight_merged_view where CAST(YEAR AS INT) IN (\"2007\",\"2008\",\"2009\") group by YEAR,DEST_STATE_ABR ORDER BY count(DEST_STATE_ABR)'))"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["**Month wise analysis of the Global recession period.**<br>\n- November 2008 and Jan 2009 observed a major fall in the number of flights."],"metadata":{}},{"cell_type":"code","source":["display(spark.sql('select distinct CAST(MONTH AS INT),COUNT(CAST(MONTH AS INT)) as NUMBER_OF_FLIGHTS ,CAST(YEAR AS INT) from flight_merged_view WHERE YEAR IN(\"2008\",\"2009\") GROUP BY CAST(MONTH AS INT),CAST(YEAR AS INT) ORDER BY CAST(YEAR AS INT),CAST(MONTH AS INT)'))"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":["**Identifying the trends in the Frequency of Flights for the Airline Carriers from 2007-2009**."],"metadata":{}},{"cell_type":"code","source":["display(spark.sql('select UNIQUE_CARRIER,COUNT(UNIQUE_CARRIER) as FREQUENCY,YEAR from flight_merged_view WHERE CAST(YEAR AS INT) IN (\"2007\",\"2008\",\"2009\") group by UNIQUE_CARRIER,YEAR ORDER BY YEAR,COUNT(UNIQUE_CARRIER) DESC'))"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["# Fraud Data Analysis over Airline Booking Transactions."],"metadata":{}},{"cell_type":"code","source":["Fraud_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/mnt/flight_data/airplane_data/Fraud_Cases.csv\")"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["display(Fraud_df)"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["Fraud_df.count()"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["Fraud_df.registerTempTable('fraud_data')"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":["**Comparison of fraudelent risk in male (i.e., 1) and female (i.e., 2) **"],"metadata":{}},{"cell_type":"code","source":["#--Comparison of fraudelent risk in male (i.e., 1) and female (i.e., 2) \ndisplay(spark.sql('select gender, count(*) as count from fraud_data f where fraudRisk=1 group by gender'))"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":["**Comparison of cardholders which are fraudelent cases**"],"metadata":{}},{"cell_type":"code","source":["#Comparison of cardholders which are fraudelent cases\ndisplay(spark.sql('select count(cardholder) as card, cardholder from fraud_data where fraudRisk=0 group by cardholder'))"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":["**Finding states which are more prone to fraudelent activities**"],"metadata":{}},{"cell_type":"code","source":["#Finding states which are more prone to fraudelent activities\ndisplay(spark.sql('select state, count(state) as state_count from fraud_data where fraudRisk in (1) group by state order by count(state)'))"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":["***********END*********"],"metadata":{}}],"metadata":{"name":"2020-05-09 - S3 Example","notebookId":1251010126247737},"nbformat":4,"nbformat_minor":0}
